{
  "name": "Object detection",
  "tagline": "",
  "body": "# Test Human Detection API\r\n\r\nAuthor: Wei Gu\r\n\r\nPlease open this document with stackedit.\r\n\r\n##Design:\r\nAssume the python tool named human_detection_api.py.\r\n\r\nall the python files are under py_scripts.\r\n###**1. Input**\r\n**FLAG SETTING:**\r\n####[1]. source file: you can only choose one mode to perform human detection\r\n**-x,--xml:** the trained xml file.\r\n**-feat,--feature:** hog/haar, what kind of feature used.\r\n**--hog_config** : hog_config.json, the json file contains the setting for hog feature:\r\nexample ( also the default setting, if you do not set config file, it will use following setting for hog feature ):\r\n\r\n    {\r\n    \"WINSIZE\":\"(96,96)\",\r\n    \"BLOCKSIZE\":\"(16,16)\",\r\n    \"BLOCKSTRIDE\":\"(8,8)\",\r\n    \"CELLSIZE\":\"(8,8)\",\r\n    \"NBINS\":\"9\",\r\n    \"winStride\" : \"(8, 8)\",\r\n    \"padding \": \"(0, 0)\",\r\n    \"scale\" : \"1.01\",\r\n    \"finalThreshold\" : \"2\"\r\n    }\r\n\r\n**--haar_config** : haar_config.json, the json file contains the setting for haar feature:\r\nexample ( also the default setting, if you do not set config file, it will use following setting for haar feature ):\r\n\r\n    {\r\n    \"SCALEFACTOR\":\"1.1\",\r\n    \"MINNEIGHBORS\": \"5\",\r\n    \"MINSIZE\":\"(30, 30)\",\r\n    \"MAXSIZE\":\"(96, 96)\",\r\n    \"FLAGS\":\"CV_HAAR_SCALE_IMAGE\"\r\n    }\r\n\r\n\r\n**-v, --video :** video file to perform human detection ( video mode, default = None )\r\n**-img, --image:** image file to perform human detection ( image mode, default = None ), if the input file path is a folder, then perform human detection on all the image files under this folder. ( **NOTES: the image file name or image directory path should contains placement name like 8600154 !!!** )\r\n**-b,--background:** background image, default = None, if you have set the background image, the api will use this image to do the background subtraction, otherwise it will generate a background first under video mode.\r\n\r\n####**2. detection on frames **\r\n--org_frame: True/False ï¼šTrue means perform human detection on the original whole frame, default = True\r\n--foreground: True/False: True means perform human detection on the foreground, default = False ( background image needed under image mode )\r\n--fgmask: True/False: True means perform human detection on the fgmask frame, default = False\r\n\r\n\r\n####**3. save result**\r\n--output_dir: the directory to save the algo result\r\n\r\n**video mode:**\r\nsuppose the video name is 8600141-2015-10-13-8600141_video_2015-10-13-14-15-38_1.3gp\r\ncurrently just show the detection results on the video.\r\n\r\n**image mode:**\r\nsuppose the image name is 8600141-2015-10-13-8600141_video_2015-10-13-14-15-38_1_2500.png\r\n\r\n[1]. draw boxes of people and save the image as : output_dir/image_result/images/8600141-2015-10-13-8600141_video_2015-10-13-14-15-38_1_2500_(hog/haar)_(origin_frame/foreground/fgmask).png\r\n\r\nsuppose the image directory is 8600141_image\r\n\r\n[2]. save the count result in a csv file ( if the input is a image directory ):\r\noutput_dir/image_result/csv_result/8600141_image_result.csv\r\nformat:\r\nimage name, human counts\r\n\r\n####**4. Example usage:**\r\n\r\n[1]. perform human detection on a image ( with/without background ):\r\nhaar feature without background subtraction:\r\n\r\n    cd py_scripts\r\n    python test_human_detection_api.py -x ../xmls/haarcascade_frontalface_default.xml -img ../test_images/face_test.png -f haar -o '/tmp/'\r\n\r\n![enter image description here](https://lh3.googleusercontent.com/-cMbQJjwPDUg/VjiEmJ3zfjI/AAAAAAAAAMA/4kebhrBulW4/s0/123.JPG \"123.JPG\")\r\n\r\nhog feature with background subtraction:\r\n\r\n    cd py_scripts\r\n     python test_human_detection_api.py -x ../xmls/stable_8600154.xml -img ../test_images/8600154_test/3050.png -f hog -b ../backgrounds/8600154_stable.png --org_frame False --foreground True -o '/tmp/'\r\n\r\n![enter image description here](https://lh3.googleusercontent.com/-vMUKk-4r9GA/VjnTkKV3D_I/AAAAAAAAAN0/r8iEe0ZM8Ak/s0/newhog.JPG \"newhog.JPG\")\r\n[2]. perform human detection on many images:\r\n\r\n       cd py_scripts\r\n       python test_human_detection_api.py -x ../xmls/stable_8600154.xml -img ../test_images/8600154_test/ --org_frame False --foreground True -b ../backgrounds/8600154_stable.png -o ~/Documents/tmp_test/\r\n\r\n\r\n  you will see the result saved under ~/Documents/tmp_test/\r\n  ![enter image description here](https://lh3.googleusercontent.com/-axBgVl2ihvg/VjnSBqEysVI/AAAAAAAAANA/1SWd1iAZgLU/s0/11112.JPG \"11112.JPG\")\r\n  ![enter image description here](https://lh3.googleusercontent.com/-ydCKA2KP7Wo/VjnSGn-huSI/AAAAAAAAANQ/aoeT7839Uv0/s0/ddfs.JPG \"ddfs.JPG\")\r\n  ![enter image description here](https://lh3.googleusercontent.com/-Crn2JdwuCHE/VjnSOzQVS-I/AAAAAAAAANc/QN3752hfzuU/s0/sdfsdf.JPG \"sdfsdf.JPG\")\r\n\r\n[3]. perform human detection on video ( hog default setting, without input background, on foreground):\r\n\r\n    cd py_scripts\r\n    python test_human_detection_api.py -x ../xmls/stable_8600154.xml -v ../videos/8600154_es-2015-07-25-17-45-01_1_89919.3gp --org_frame False --foreground True\r\nyou will see a window shows the background generated, and a dynamic window shows the detection result.![enter image description here](https://lh3.googleusercontent.com/-y1w4RoUxaaw/VjnOuXurTwI/AAAAAAAAAMw/6Zr7qHAwOFQ/s0/dya.JPG \"dya.JPG\")\r\n\r\n\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}