<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Object detection by AloneGu</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Object detection</h1>
        <p></p>

        <p class="view"><a href="https://github.com/AloneGu/object_detection">View the Project on GitHub <small>AloneGu/object_detection</small></a></p>


        <ul>
          <li><a href="https://github.com/AloneGu/object_detection/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/AloneGu/object_detection/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/AloneGu/object_detection">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <h1>
<a id="test-human-detection-api" class="anchor" href="#test-human-detection-api" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Test Human Detection API</h1>

<p>Author: Wei Gu</p>

<p>Please open this document with stackedit.</p>

<h2>
<a id="design" class="anchor" href="#design" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Design:</h2>

<p>Assume the python tool named human_detection_api.py.</p>

<p>all the python files are under py_scripts.</p>

<h3>
<a id="1-input" class="anchor" href="#1-input" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>1. Input</strong>
</h3>

<p><strong>FLAG SETTING:</strong></p>

<h4>
<a id="1-source-file-you-can-only-choose-one-mode-to-perform-human-detection" class="anchor" href="#1-source-file-you-can-only-choose-one-mode-to-perform-human-detection" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>[1]. source file: you can only choose one mode to perform human detection</h4>

<p><strong>-x,--xml:</strong> the trained xml file.
<strong>-feat,--feature:</strong> hog/haar, what kind of feature used.
<strong>--hog_config</strong> : hog_config.json, the json file contains the setting for hog feature:
example ( also the default setting, if you do not set config file, it will use following setting for hog feature ):</p>

<pre><code>{
"WINSIZE":"(96,96)",
"BLOCKSIZE":"(16,16)",
"BLOCKSTRIDE":"(8,8)",
"CELLSIZE":"(8,8)",
"NBINS":"9",
"winStride" : "(8, 8)",
"padding ": "(0, 0)",
"scale" : "1.01",
"finalThreshold" : "2"
}
</code></pre>

<p><strong>--haar_config</strong> : haar_config.json, the json file contains the setting for haar feature:
example ( also the default setting, if you do not set config file, it will use following setting for haar feature ):</p>

<pre><code>{
"SCALEFACTOR":"1.1",
"MINNEIGHBORS": "5",
"MINSIZE":"(30, 30)",
"MAXSIZE":"(96, 96)",
"FLAGS":"CV_HAAR_SCALE_IMAGE"
}
</code></pre>

<p><strong>-v, --video :</strong> video file to perform human detection ( video mode, default = None )
<strong>-img, --image:</strong> image file to perform human detection ( image mode, default = None ), if the input file path is a folder, then perform human detection on all the image files under this folder. ( <strong>NOTES: the image file name or image directory path should contains placement name like 8600154 !!!</strong> )
<strong>-b,--background:</strong> background image, default = None, if you have set the background image, the api will use this image to do the background subtraction, otherwise it will generate a background first under video mode.</p>

<h4>
<a id="2-detection-on-frames-" class="anchor" href="#2-detection-on-frames-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>*<em>2. detection on frames *</em>
</h4>

<p>--org_frame: True/False ï¼šTrue means perform human detection on the original whole frame, default = True
--foreground: True/False: True means perform human detection on the foreground, default = False ( background image needed under image mode )
--fgmask: True/False: True means perform human detection on the fgmask frame, default = False</p>

<h4>
<a id="3-save-result" class="anchor" href="#3-save-result" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>3. save result</strong>
</h4>

<p>--output_dir: the directory to save the algo result</p>

<p><strong>video mode:</strong>
suppose the video name is 8600141-2015-10-13-8600141_video_2015-10-13-14-15-38_1.3gp
currently just show the detection results on the video.</p>

<p><strong>image mode:</strong>
suppose the image name is 8600141-2015-10-13-8600141_video_2015-10-13-14-15-38_1_2500.png</p>

<p>[1]. draw boxes of people and save the image as : output_dir/image_result/images/8600141-2015-10-13-8600141_video_2015-10-13-14-15-38_1_2500_(hog/haar)_(origin_frame/foreground/fgmask).png</p>

<p>suppose the image directory is 8600141_image</p>

<p>[2]. save the count result in a csv file ( if the input is a image directory ):
output_dir/image_result/csv_result/8600141_image_result.csv
format:
image name, human counts</p>

<h4>
<a id="4-example-usage" class="anchor" href="#4-example-usage" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>4. Example usage:</strong>
</h4>

<p>[1]. perform human detection on a image ( with/without background ):
haar feature without background subtraction:</p>

<pre><code>cd py_scripts
python test_human_detection_api.py -x ../xmls/haarcascade_frontalface_default.xml -img ../test_images/face_test.png -f haar -o '/tmp/'
</code></pre>

<p><img src="https://lh3.googleusercontent.com/-cMbQJjwPDUg/VjiEmJ3zfjI/AAAAAAAAAMA/4kebhrBulW4/s0/123.JPG" alt="enter image description here" title="123.JPG"></p>

<p>hog feature with background subtraction:</p>

<pre><code>cd py_scripts
 python test_human_detection_api.py -x ../xmls/stable_8600154.xml -img ../test_images/8600154_test/3050.png -f hog -b ../backgrounds/8600154_stable.png --org_frame False --foreground True -o '/tmp/'
</code></pre>

<p><img src="https://lh3.googleusercontent.com/-vMUKk-4r9GA/VjnTkKV3D_I/AAAAAAAAAN0/r8iEe0ZM8Ak/s0/newhog.JPG" alt="enter image description here" title="newhog.JPG">
[2]. perform human detection on many images:</p>

<pre><code>   cd py_scripts
   python test_human_detection_api.py -x ../xmls/stable_8600154.xml -img ../test_images/8600154_test/ --org_frame False --foreground True -b ../backgrounds/8600154_stable.png -o ~/Documents/tmp_test/
</code></pre>

<p>you will see the result saved under ~/Documents/tmp_test/
  <img src="https://lh3.googleusercontent.com/-axBgVl2ihvg/VjnSBqEysVI/AAAAAAAAANA/1SWd1iAZgLU/s0/11112.JPG" alt="enter image description here" title="11112.JPG">
  <img src="https://lh3.googleusercontent.com/-ydCKA2KP7Wo/VjnSGn-huSI/AAAAAAAAANQ/aoeT7839Uv0/s0/ddfs.JPG" alt="enter image description here" title="ddfs.JPG">
  <img src="https://lh3.googleusercontent.com/-Crn2JdwuCHE/VjnSOzQVS-I/AAAAAAAAANc/QN3752hfzuU/s0/sdfsdf.JPG" alt="enter image description here" title="sdfsdf.JPG"></p>

<p>[3]. perform human detection on video ( hog default setting, without input background, on foreground):</p>

<pre><code>cd py_scripts
python test_human_detection_api.py -x ../xmls/stable_8600154.xml -v ../videos/8600154_es-2015-07-25-17-45-01_1_89919.3gp --org_frame False --foreground True
</code></pre>

<p>you will see a window shows the background generated, and a dynamic window shows the detection result.<img src="https://lh3.googleusercontent.com/-y1w4RoUxaaw/VjnOuXurTwI/AAAAAAAAAMw/6Zr7qHAwOFQ/s0/dya.JPG" alt="enter image description here" title="dya.JPG"></p>
      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/AloneGu">AloneGu</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>
